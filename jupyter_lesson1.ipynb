{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4586e1-f486-4bc8-b557-e49ce5f72666",
   "metadata": {},
   "source": [
    "Тема “Вычисления с помощью Numpy”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0354118-96ef-4685-a332-a078d6af9499",
   "metadata": {},
   "source": [
    "Задание 1\n",
    "Импортируйте библиотеку Numpy и дайте ей псевдоним np.\n",
    "Создайте массив Numpy под названием a размером 5x2, то есть состоящий из 5 строк и 2 столбцов. Первый столбец должен содержать числа 1, 2, 3, 3, 1, а второй - числа 6, 8, 11, 10, 7. Будем считать, что каждый столбец - это признак, а строка - наблюдение. Затем найдите среднее значение по каждому признаку, используя метод mean массива Numpy. Результат запишите в массив mean_a, в нем должно быть 2 элемента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7680dd74-82e6-464d-9da9-02a52c125794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  6]\n",
      " [ 2  8]\n",
      " [ 3 11]\n",
      " [ 3 10]\n",
      " [ 1  7]] shape = (5, 2)\n"
     ]
    }
   ],
   "source": [
    "#import numpy\n",
    "import numpy as np\n",
    "\n",
    "# create ndarray\n",
    "column_1 = [1, 2, 3, 3, 1]\n",
    "column_2 = [6, 8, 11, 10, 7]\n",
    "left_a = np.asarray(column_1).reshape(len(column_1), -1)\n",
    "right_a = np.asarray(column_2).reshape(len(column_2), -1)\n",
    "a = np.concatenate([left_a, right_a], axis=-1)\n",
    "print(a, \"shape =\", a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d35b87d-0dfc-4ecc-989c-c7643061a693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.  8.4]\n"
     ]
    }
   ],
   "source": [
    "# find mean value along columns\n",
    "\n",
    "mean_a = np.mean(a, axis=0)\n",
    "print(mean_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bd1eac-a8ba-4789-92de-a869a1d04d2b",
   "metadata": {},
   "source": [
    "Задание 2\n",
    "Вычислите массив a_centered, отняв от значений массива “а” средние значения соответствующих признаков, содержащиеся в массиве mean_a. Вычисление должно производиться в одно действие. Получившийся массив должен иметь размер 5x2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6716fc56-d630-421e-8720-fd356d14e7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  -2.4]\n",
      " [ 0.  -0.4]\n",
      " [ 1.   2.6]\n",
      " [ 1.   1.6]\n",
      " [-1.  -1.4]] shape = (5, 2)\n"
     ]
    }
   ],
   "source": [
    "a_centered = a - mean_a\n",
    "print(a_centered, \"shape =\", a_centered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55676209-a7c6-4bd2-bf23-3e092ba7f7e1",
   "metadata": {},
   "source": [
    "Задание 3\n",
    "Найдите скалярное произведение столбцов массива a_centered. В результате должна получиться величина a_centered_sp. Затем поделите a_centered_sp на N-1, где N - число наблюдений.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0cfbe37-aab3-406e-ba54-606d4e1cf5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "a_centered_sp = np.multiply(a_centered[:,0], a_centered[:,1]).sum()\n",
    "print(a_centered_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90be463d-02d6-4fb1-a522-c08602020c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "result = a_centered_sp / (a.shape[0] - 1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a77d74d-f520-4da5-9c34-896ec7a5f203",
   "metadata": {},
   "source": [
    "Тема “Работа с данными в Pandas”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760be1d-d4f1-42ff-b711-4e7bf09cf6b1",
   "metadata": {},
   "source": [
    "Задание 1\n",
    "Импортируйте библиотеку Pandas и дайте ей псевдоним pd. Создайте датафрейм authors со столбцами author_id и author_name, в которых соответственно содержатся данные: [1, 2, 3] и ['Тургенев', 'Чехов', 'Островский'].\n",
    "Затем создайте датафрейм book cо столбцами author_id, book_title и price, в которых соответственно содержатся данные:  \n",
    "[1, 1, 1, 2, 2, 3, 3],\n",
    "['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и поклонники'],\n",
    "[450, 300, 350, 500, 450, 370, 290]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4084d3c-9fd3-4dff-abae-3ec11315fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d62bedb9-84f5-46bb-a5c1-9b3173954a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id author_name\n",
      "0          1    Тургенев\n",
      "1          2       Чехов\n",
      "2          3  Островский\n"
     ]
    }
   ],
   "source": [
    "# creating dataframe authors\n",
    "data = {\"author_id\": [1, 2, 3], \"author_name\": ['Тургенев', 'Чехов', 'Островский']}\n",
    "authors = pd.DataFrame(data=data)\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2efcd9d6-84c7-48ed-8ff5-8015e8da96b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id            book_title  price\n",
      "0          1           Отцы и дети    450\n",
      "1          1                 Рудин    300\n",
      "2          1     Дворянское гнездо    350\n",
      "3          2      Толстый и тонкий    500\n",
      "4          2       Дама с собачкой    450\n",
      "5          3                 Гроза    370\n",
      "6          3  Таланты и поклонники    290\n"
     ]
    }
   ],
   "source": [
    "# creating dataframe book\n",
    "book_data = {\"author_id\": [1, 1, 1, 2, 2, 3, 3], \n",
    "             \"book_title\": ['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и поклонники'],\n",
    "             \"price\": [450, 300, 350, 500, 450, 370, 290]}\n",
    "book = pd.DataFrame(data=book_data)\n",
    "print(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd8783-a4d5-42a1-a9df-31b224f40248",
   "metadata": {},
   "source": [
    "Задание 2\n",
    "Получите датафрейм authors_price, соединив датафреймы authors и books по полю author_id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adc9d608-b3b2-4a63-88e0-854dff00ba94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id author_name            book_title  price\n",
      "0          1    Тургенев           Отцы и дети    450\n",
      "1          1    Тургенев                 Рудин    300\n",
      "2          1    Тургенев     Дворянское гнездо    350\n",
      "3          2       Чехов      Толстый и тонкий    500\n",
      "4          2       Чехов       Дама с собачкой    450\n",
      "5          3  Островский                 Гроза    370\n",
      "6          3  Островский  Таланты и поклонники    290\n"
     ]
    }
   ],
   "source": [
    "authors_price = pd.merge(authors,\n",
    "                        book,\n",
    "                        on=\"author_id\")\n",
    "print(authors_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e45806-03b3-4318-bebd-99368eb00149",
   "metadata": {},
   "source": [
    "Задание 3\n",
    "Создайте датафрейм top5, в котором содержатся строки из authors_price с пятью самыми дорогими книгами.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80fb64c4-a292-401c-87fd-cae2320d3a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id author_name         book_title  price\n",
      "3          2       Чехов   Толстый и тонкий    500\n",
      "0          1    Тургенев        Отцы и дети    450\n",
      "4          2       Чехов    Дама с собачкой    450\n",
      "5          3  Островский              Гроза    370\n",
      "2          1    Тургенев  Дворянское гнездо    350\n"
     ]
    }
   ],
   "source": [
    "top5 = authors_price.sort_values(by=\"price\", ascending=False).head(5)\n",
    "print(top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4283b-7986-4eb7-a604-033530a18b7a",
   "metadata": {},
   "source": [
    "Задание 4\n",
    "Создайте датафрейм authors_stat на основе информации из authors_price. В датафрейме authors_stat должны быть четыре столбца:\n",
    "author_name, min_price, max_price и mean_price,\n",
    "в которых должны содержаться соответственно имя автора, минимальная, максимальная и средняя цена на книги этого автора.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56e31deb-38c5-4a39-9463-5ec3a9bcc081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id author_name            book_title  price\n",
      "0          1    Тургенев           Отцы и дети    450\n",
      "1          1    Тургенев                 Рудин    300\n",
      "2          1    Тургенев     Дворянское гнездо    350\n",
      "3          2       Чехов      Толстый и тонкий    500\n",
      "4          2       Чехов       Дама с собачкой    450\n",
      "5          3  Островский                 Гроза    370\n",
      "6          3  Островский  Таланты и поклонники    290\n",
      "{'Тургенев', 'Чехов', 'Островский'}\n"
     ]
    }
   ],
   "source": [
    "print(authors_price)\n",
    "author_name = set(authors_price['author_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8979dfb5-1ee1-477b-8bc0-1dbc8d9b8f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  author_name min_price max_price  mean_price\n",
      "0    Тургенев       300       450  366.666667\n",
      "1       Чехов       450       500  475.000000\n",
      "2  Островский       290       370  330.000000\n"
     ]
    }
   ],
   "source": [
    "authors_stat = pd.DataFrame(columns=[\"author_name\", \"min_price\", \"max_price\", \"mean_price\"])\n",
    "for name in author_name:\n",
    "    author_info = authors_price[authors_price['author_name'] == name]\n",
    "    prices = author_info['price']\n",
    "    mean_price = prices.mean()\n",
    "    min_price = prices.min()\n",
    "    max_price = prices.max()\n",
    "    authors_stat = authors_stat.append({\"author_name\": name, \"min_price\": min_price, \"max_price\": max_price, \"mean_price\": mean_price}, ignore_index=True)\n",
    "print(authors_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd07f0-dfeb-4241-9873-2ac2587b6cc6",
   "metadata": {},
   "source": [
    "Задание 5**\n",
    "Создайте новый столбец в датафрейме authors_price под названием cover, в нем будут располагаться данные о том, какая обложка у данной книги - твердая или мягкая. В этот столбец поместите данные из следующего списка:\n",
    "['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая'].\n",
    "Просмотрите документацию по функции pd.pivot_table с помощью вопросительного знака.Для каждого автора посчитайте суммарную стоимость книг в твердой и мягкой обложке. Используйте для этого функцию pd.pivot_table. При этом столбцы должны называться \"твердая\" и \"мягкая\", а индексами должны быть фамилии авторов. Пропущенные значения стоимостей заполните нулями, при необходимости загрузите библиотеку Numpy.\n",
    "Назовите полученный датасет book_info и сохраните его в формат pickle под названием \"book_info.pkl\". Затем загрузите из этого файла датафрейм и назовите его book_info2. Удостоверьтесь, что датафреймы book_info и book_info2 идентичны.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0f522da-727d-4f2c-8529-0dff2d9d46f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id author_name            book_title  price    cover\n",
      "0          1    Тургенев           Отцы и дети    450  твердая\n",
      "1          1    Тургенев                 Рудин    300   мягкая\n",
      "2          1    Тургенев     Дворянское гнездо    350   мягкая\n",
      "3          2       Чехов      Толстый и тонкий    500  твердая\n",
      "4          2       Чехов       Дама с собачкой    450  твердая\n",
      "5          3  Островский                 Гроза    370   мягкая\n",
      "6          3  Островский  Таланты и поклонники    290   мягкая\n"
     ]
    }
   ],
   "source": [
    "cover_df = pd.DataFrame({\"cover\": ['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая']})\n",
    "authors_price = authors_price.join(cover_df)\n",
    "print(authors_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b47c28f-f82b-449c-86cc-7c519dd3b449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       " \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maggfunc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'AggFuncType'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmargins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmargins_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'All'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Create a spreadsheet-style pivot table as a DataFrame.\n",
       "\n",
       "The levels in the pivot table will be stored in MultiIndex objects\n",
       "(hierarchical indexes) on the index and columns of the result DataFrame.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data : DataFrame\n",
       "values : column to aggregate, optional\n",
       "index : column, Grouper, array, or list of the previous\n",
       "    If an array is passed, it must be the same length as the data. The\n",
       "    list can contain any of the other types (except list).\n",
       "    Keys to group by on the pivot table index.  If an array is passed,\n",
       "    it is being used as the same manner as column values.\n",
       "columns : column, Grouper, array, or list of the previous\n",
       "    If an array is passed, it must be the same length as the data. The\n",
       "    list can contain any of the other types (except list).\n",
       "    Keys to group by on the pivot table column.  If an array is passed,\n",
       "    it is being used as the same manner as column values.\n",
       "aggfunc : function, list of functions, dict, default numpy.mean\n",
       "    If list of functions passed, the resulting pivot table will have\n",
       "    hierarchical columns whose top level are the function names\n",
       "    (inferred from the function objects themselves)\n",
       "    If dict is passed, the key is column to aggregate and value\n",
       "    is function or list of functions.\n",
       "fill_value : scalar, default None\n",
       "    Value to replace missing values with (in the resulting pivot table,\n",
       "    after aggregation).\n",
       "margins : bool, default False\n",
       "    Add all row / columns (e.g. for subtotal / grand totals).\n",
       "dropna : bool, default True\n",
       "    Do not include columns whose entries are all NaN.\n",
       "margins_name : str, default 'All'\n",
       "    Name of the row / column that will contain the totals\n",
       "    when margins is True.\n",
       "observed : bool, default False\n",
       "    This only applies if any of the groupers are Categoricals.\n",
       "    If True: only show observed values for categorical groupers.\n",
       "    If False: show all values for categorical groupers.\n",
       "\n",
       "    .. versionchanged:: 0.25.0\n",
       "\n",
       "sort : bool, default True\n",
       "    Specifies if the result should be sorted.\n",
       "\n",
       "    .. versionadded:: 1.3.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame\n",
       "    An Excel style pivot table.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.pivot : Pivot without aggregation that can handle\n",
       "    non-numeric data.\n",
       "DataFrame.melt: Unpivot a DataFrame from wide to long format,\n",
       "    optionally leaving identifiers set.\n",
       "wide_to_long : Wide panel to long format. Less flexible but more\n",
       "    user-friendly than melt.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
       "...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
       "...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
       "...                          \"one\", \"one\", \"two\", \"two\"],\n",
       "...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
       "...                          \"small\", \"large\", \"small\", \"small\",\n",
       "...                          \"large\"],\n",
       "...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
       "...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
       ">>> df\n",
       "     A    B      C  D  E\n",
       "0  foo  one  small  1  2\n",
       "1  foo  one  large  2  4\n",
       "2  foo  one  large  2  5\n",
       "3  foo  two  small  3  5\n",
       "4  foo  two  small  3  6\n",
       "5  bar  one  large  4  6\n",
       "6  bar  one  small  5  8\n",
       "7  bar  two  small  6  9\n",
       "8  bar  two  large  7  9\n",
       "\n",
       "This first example aggregates values by taking the sum.\n",
       "\n",
       ">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
       "...                     columns=['C'], aggfunc=np.sum)\n",
       ">>> table\n",
       "C        large  small\n",
       "A   B\n",
       "bar one    4.0    5.0\n",
       "    two    7.0    6.0\n",
       "foo one    4.0    1.0\n",
       "    two    NaN    6.0\n",
       "\n",
       "We can also fill missing values using the `fill_value` parameter.\n",
       "\n",
       ">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
       "...                     columns=['C'], aggfunc=np.sum, fill_value=0)\n",
       ">>> table\n",
       "C        large  small\n",
       "A   B\n",
       "bar one      4      5\n",
       "    two      7      6\n",
       "foo one      4      1\n",
       "    two      0      6\n",
       "\n",
       "The next example aggregates by taking the mean across multiple columns.\n",
       "\n",
       ">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
       "...                     aggfunc={'D': np.mean,\n",
       "...                              'E': np.mean})\n",
       ">>> table\n",
       "                D         E\n",
       "A   C\n",
       "bar large  5.500000  7.500000\n",
       "    small  5.500000  8.500000\n",
       "foo large  2.000000  4.500000\n",
       "    small  2.333333  4.333333\n",
       "\n",
       "We can also calculate multiple types of aggregations for any given\n",
       "value column.\n",
       "\n",
       ">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
       "...                     aggfunc={'D': np.mean,\n",
       "...                              'E': [min, max, np.mean]})\n",
       ">>> table\n",
       "                D    E\n",
       "            mean  max      mean  min\n",
       "A   C\n",
       "bar large  5.500000  9.0  7.500000  6.0\n",
       "    small  5.500000  9.0  8.500000  8.0\n",
       "foo large  2.000000  5.0  4.500000  4.0\n",
       "    small  2.333333  6.0  4.333333  2.0\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\pycharmprojects\\jupiter\\venv\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? pd.pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0053497a-ee92-4ed2-8a77-21bf27b7d25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cover        мягкая  твердая\n",
      "author_name                 \n",
      "Островский      330        0\n",
      "Тургенев        325      450\n",
      "Чехов             0      475\n"
     ]
    }
   ],
   "source": [
    "book_info = pd.pivot_table(authors_price, \n",
    "                           values=\"price\", \n",
    "                           index=[\"author_name\"],\n",
    "                           columns=[\"cover\"], \n",
    "                           fill_value = 0,\n",
    "                           aggfunc=np.mean\n",
    "                          )\n",
    "print(price_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "42211308-0faa-406f-8da6-969f94f14a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_filename = \"book_info.pkl\"\n",
    "book_info.to_pickle(save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09a78584-1150-4244-8f8e-56eaae03758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_info2 = pd.read_pickle(save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "362bb526-7c5a-4766-95a1-a7b85bf07815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cover        мягкая  твердая\n",
      "author_name                 \n",
      "Островский      330        0\n",
      "Тургенев        325      450\n",
      "Чехов             0      475\n"
     ]
    }
   ],
   "source": [
    "print(book_info2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab17411-107c-4b90-a590-08d8b42aa0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
